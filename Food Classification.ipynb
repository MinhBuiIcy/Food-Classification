{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T04:46:51.600247Z",
     "iopub.status.busy": "2024-12-13T04:46:51.599626Z",
     "iopub.status.idle": "2024-12-13T04:47:05.424368Z",
     "shell.execute_reply": "2024-12-13T04:47:05.423401Z",
     "shell.execute_reply.started": "2024-12-13T04:46:51.600208Z"
    },
    "id": "LT2MhFArf8iH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, SeparableConv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D,\n",
    "    BatchNormalization, Activation, Dense, Dropout, Flatten, Multiply, Add, Lambda, SpatialDropout2D, Reshape, GlobalMaxPooling2D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import HeNormal, GlorotNormal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from tensorflow.keras.optimizers.schedules import (\n",
    "    ExponentialDecay,\n",
    "    PolynomialDecay,\n",
    "    PiecewiseConstantDecay,\n",
    "    CosineDecay,\n",
    "    CosineDecayRestarts,\n",
    "    InverseTimeDecay,\n",
    "    LearningRateSchedule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T04:47:07.861672Z",
     "iopub.status.busy": "2024-12-13T04:47:07.861030Z",
     "iopub.status.idle": "2024-12-13T04:47:20.094343Z",
     "shell.execute_reply": "2024-12-13T04:47:20.093060Z",
     "shell.execute_reply.started": "2024-12-13T04:47:07.861637Z"
    },
    "id": "-ExRPhfvnA41",
    "outputId": "0f08df82-a764-4658-8538-cb56fa6f55d4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "import gdown\n",
    "\n",
    "file_id = ''\n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', 'downloaded_file.zip', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:22:10.617985Z",
     "iopub.status.busy": "2024-12-12T17:22:10.617058Z",
     "iopub.status.idle": "2024-12-12T17:22:52.389196Z",
     "shell.execute_reply": "2024-12-12T17:22:52.388055Z",
     "shell.execute_reply.started": "2024-12-12T17:22:10.617935Z"
    },
    "id": "Yn2XvIItpG05",
    "outputId": "bca8c5ee-99d5-47be-bbcc-798a4390b686",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!unzip -q /kaggle/working/downloaded_file.zip -d extracted_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:23:09.666214Z",
     "iopub.status.busy": "2024-12-12T17:23:09.665796Z",
     "iopub.status.idle": "2024-12-12T17:23:09.678689Z",
     "shell.execute_reply": "2024-12-12T17:23:09.677671Z",
     "shell.execute_reply.started": "2024-12-12T17:23:09.666175Z"
    },
    "id": "aMICgGLOf8iI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(data_dir, batch_size=16, validation_split=0.2):\n",
    "    \"\"\"Create train and validation datasets with a split.\"\"\"\n",
    "    data_dir = pathlib.Path(data_dir)\n",
    "    all_image_paths = list(data_dir.glob('*/*.jpg'))\n",
    "    all_image_paths = [str(path) for path in all_image_paths]\n",
    "    class_names = sorted([item.name for item in data_dir.glob('*') if item.is_dir()])\n",
    "    class_names = tf.constant(class_names)\n",
    "\n",
    "    # Shuffle the paths\n",
    "    total_images = len(all_image_paths)\n",
    "    tf.random.set_seed(42)  # Ensure reproducibility\n",
    "    all_image_paths = tf.random.shuffle(all_image_paths)\n",
    "\n",
    "    # Compute split index\n",
    "    val_size = int(total_images * validation_split)\n",
    "    train_paths = all_image_paths[val_size:]\n",
    "    val_paths = all_image_paths[:val_size]\n",
    "\n",
    "    # Create label functions\n",
    "    def get_label(file_path):\n",
    "        parts = tf.strings.split(file_path, '/')\n",
    "        class_name = parts[-2]\n",
    "        label = tf.argmax(tf.cast(class_names == class_name, tf.int32))\n",
    "        return label\n",
    "\n",
    "    def process_image(file_path, label, augment=False):\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "\n",
    "        if augment:\n",
    "            # Apply data augmentation\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "            image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "            image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "\n",
    "        image = image / 127.5 - 1.0\n",
    "        return image, label\n",
    "\n",
    "    def prepare_dataset(paths, augment=False):\n",
    "        paths_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "        labels_ds = paths_ds.map(get_label)\n",
    "        dataset = tf.data.Dataset.zip((paths_ds, labels_ds))\n",
    "        dataset = dataset.map(lambda x, y: process_image(x, y, augment=augment))\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    # Create train and validation datasets\n",
    "    train_dataset = prepare_dataset(train_paths, augment=True)  # Augmentation applied\n",
    "    val_dataset = prepare_dataset(val_paths, augment=False)     # No augmentation for validation\n",
    "\n",
    "    return train_dataset, val_dataset, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:23:14.715336Z",
     "iopub.status.busy": "2024-12-12T17:23:14.714639Z",
     "iopub.status.idle": "2024-12-12T17:23:17.981269Z",
     "shell.execute_reply": "2024-12-12T17:23:17.980326Z",
     "shell.execute_reply.started": "2024-12-12T17:23:14.715298Z"
    },
    "id": "QOcNB8nyf8iJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "data_dir = \"extracted_folder/content/food_dataset/data\"\n",
    "batch_size = 128\n",
    "train_dataset, val_dataset, class_names = create_dataset(data_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:23:22.212136Z",
     "iopub.status.busy": "2024-12-12T17:23:22.211743Z",
     "iopub.status.idle": "2024-12-12T17:23:31.330925Z",
     "shell.execute_reply": "2024-12-12T17:23:31.330061Z",
     "shell.execute_reply.started": "2024-12-12T17:23:22.212105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for images, labels in train_dataset.take(1):  # Fetch one batch\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"First label in the batch: {labels[0]}\")\n",
    "\n",
    "# Display some images with labels\n",
    "def display_images_with_labels(dataset, class_names, num_images=15):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(num_images):\n",
    "            ax = plt.subplot(3, 5, i + 1)\n",
    "            plt.imshow(images[i].numpy())\n",
    "            plt.title(class_names[labels[i].numpy()].numpy().decode(\"utf-8\"))\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to display images\n",
    "display_images_with_labels(train_dataset, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:23:41.318518Z",
     "iopub.status.busy": "2024-12-12T17:23:41.317857Z",
     "iopub.status.idle": "2024-12-12T17:23:41.323341Z",
     "shell.execute_reply": "2024-12-12T17:23:41.322396Z",
     "shell.execute_reply.started": "2024-12-12T17:23:41.318481Z"
    },
    "id": "H4u2TXfUIVef",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def se_block(input_tensor, reduction=16):\n",
    "    filters = input_tensor.shape[-1]\n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Dense(filters // reduction, activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-3))(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer=GlorotNormal(), kernel_regularizer=l2(1e-3))(se)\n",
    "    return Multiply()([input_tensor, se])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:23:44.967890Z",
     "iopub.status.busy": "2024-12-12T17:23:44.967182Z",
     "iopub.status.idle": "2024-12-12T17:23:44.975190Z",
     "shell.execute_reply": "2024-12-12T17:23:44.974298Z",
     "shell.execute_reply.started": "2024-12-12T17:23:44.967854Z"
    },
    "id": "bIk3dqeVFNLi",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cbam_block(input_tensor, reduction_ratio=16):\n",
    "    \"\"\"CBAM block for feature refinement.\"\"\"\n",
    "    # Channel Attention\n",
    "    channel_avg_pool = GlobalAveragePooling2D()(input_tensor)\n",
    "    channel_max_pool = GlobalMaxPooling2D()(input_tensor)\n",
    "\n",
    "    channel_avg_pool = Dense(input_tensor.shape[-1] // reduction_ratio, activation='relu')(channel_avg_pool)\n",
    "    channel_avg_pool = Dense(input_tensor.shape[-1], activation='sigmoid')(channel_avg_pool)\n",
    "\n",
    "    channel_max_pool = Dense(input_tensor.shape[-1] // reduction_ratio, activation='relu')(channel_max_pool)\n",
    "    channel_max_pool = Dense(input_tensor.shape[-1], activation='sigmoid')(channel_max_pool)\n",
    "\n",
    "    channel_avg_pool = Reshape((1, 1, input_tensor.shape[-1]))(channel_avg_pool)\n",
    "    channel_max_pool = Reshape((1, 1, input_tensor.shape[-1]))(channel_max_pool)\n",
    "\n",
    "    channel_attention = Add()([channel_avg_pool, channel_max_pool])\n",
    "    channel_attention = Multiply()([input_tensor, channel_attention])\n",
    "\n",
    "    # Spatial Attention\n",
    "    def spatial_attention(inputs):\n",
    "        avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "        max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)\n",
    "        return tf.concat([avg_pool, max_pool], axis=-1)\n",
    "\n",
    "    spatial_attention = Lambda(spatial_attention)(channel_attention)\n",
    "    spatial_attention = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(spatial_attention)\n",
    "    spatial_attention = Multiply()([channel_attention, spatial_attention])\n",
    "\n",
    "    return spatial_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:23:47.778396Z",
     "iopub.status.busy": "2024-12-12T17:23:47.777612Z",
     "iopub.status.idle": "2024-12-12T17:23:47.788923Z",
     "shell.execute_reply": "2024-12-12T17:23:47.788085Z",
     "shell.execute_reply.started": "2024-12-12T17:23:47.778359Z"
    },
    "id": "UKpV5Uwif8iK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def inception_block_with_residual(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj, scale=0.2):\n",
    "    # Save the input for residual connection\n",
    "    shortcut = x\n",
    "\n",
    "    # 1x1 Convolution\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-3))(x)\n",
    "    conv_1x1 = BatchNormalization()(conv_1x1)\n",
    "    conv_1x1 = SpatialDropout2D(0.2)(conv_1x1)\n",
    "\n",
    "    # 3x3 Convolution\n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-3))(x)\n",
    "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-3))(conv_3x3)\n",
    "    conv_3x3 = BatchNormalization()(conv_3x3)\n",
    "    conv_3x3 = SpatialDropout2D(0.2)(conv_3x3)\n",
    "\n",
    "    # 5x5 Convolution\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-3))(x)\n",
    "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-3))(conv_5x5)\n",
    "    conv_5x5 = BatchNormalization()(conv_5x5)\n",
    "    conv_5x5 = SpatialDropout2D(0.2)(conv_5x5)\n",
    "\n",
    "    # Max Pooling + 1x1 Convolution\n",
    "    pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-3))(pool_proj)\n",
    "    pool_proj = BatchNormalization()(pool_proj)\n",
    "    pool_proj = SpatialDropout2D(0.2)(pool_proj)\n",
    "\n",
    "    # Concatenate all branches\n",
    "    output = tf.keras.layers.Concatenate()([conv_1x1, conv_3x3, conv_5x5, pool_proj])\n",
    "\n",
    "    # Apply Dropout after concatenation\n",
    "    output = Dropout(0.3)(output)\n",
    "\n",
    "    # Add SE block\n",
    "    output = cbam_block(output)\n",
    "\n",
    "    # Add residual connection if dimensions match\n",
    "    if shortcut.shape[-1] != output.shape[-1]:  # Match dimensions using 1x1 conv\n",
    "        shortcut = Conv2D(output.shape[-1], (1, 1), padding='same', kernel_initializer=HeNormal())(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    scaled_output = tf.keras.layers.Lambda(lambda s: s * scale)(output)\n",
    "\n",
    "    output = tf.keras.layers.Add()([shortcut, scaled_output])\n",
    "    output = Activation('relu')(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:23:51.511064Z",
     "iopub.status.busy": "2024-12-12T17:23:51.510222Z",
     "iopub.status.idle": "2024-12-12T17:23:51.515778Z",
     "shell.execute_reply": "2024-12-12T17:23:51.514950Z",
     "shell.execute_reply.started": "2024-12-12T17:23:51.511026Z"
    },
    "id": "MYG-xtlxIflD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def auxiliary_classifier(x, num_classes):\n",
    "    aux = AveragePooling2D((5, 5), strides=(3, 3))(x)\n",
    "    aux = Conv2D(64, (1, 1), padding='same', activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-3))(aux)\n",
    "    aux = Dropout(0.5)(aux)\n",
    "    aux = Flatten()(aux)\n",
    "    aux = Dense(num_classes, activation='softmax', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-3))(aux)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:23:54.767138Z",
     "iopub.status.busy": "2024-12-12T17:23:54.766794Z",
     "iopub.status.idle": "2024-12-12T17:23:56.180920Z",
     "shell.execute_reply": "2024-12-12T17:23:56.180198Z",
     "shell.execute_reply.started": "2024-12-12T17:23:54.767108Z"
    },
    "id": "13V4TESjHvS5",
    "outputId": "543b1a7e-6622-4853-a352-7a0218af6390",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def GoogleNet(input_shape=(224, 224, 3), num_classes=1000):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    initializer = HeNormal()\n",
    "\n",
    "    # Initial layers\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(1e-3))(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SpatialDropout2D(0.1)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = Conv2D(64, (1, 1), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(1e-3))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SpatialDropout2D(0.1)(x)\n",
    "    x = Conv2D(192, (3, 3), padding='same', kernel_initializer=initializer, kernel_regularizer=l2(1e-3))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SpatialDropout2D(0.1)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Inception blocks with auxiliary classifiers\n",
    "    x = inception_block_with_residual(x, 64, 96, 128, 16, 32, 32)\n",
    "    aux_output1 = auxiliary_classifier(x, num_classes)\n",
    "\n",
    "    x = inception_block_with_residual(x, 128, 128, 192, 32, 96, 64)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_block_with_residual(x, 192, 96, 208, 16, 48, 64)\n",
    "    x = inception_block_with_residual(x, 160, 112, 224, 24, 64, 64)\n",
    "    x = inception_block_with_residual(x, 128, 128, 256, 24, 64, 64)\n",
    "    aux_output2 = auxiliary_classifier(x, num_classes)\n",
    "\n",
    "    x = inception_block_with_residual(x, 112, 144, 288, 32, 64, 64)\n",
    "    x = inception_block_with_residual(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = inception_block_with_residual(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = inception_block_with_residual(x, 384, 192, 384, 48, 128, 128)\n",
    "    x = AveragePooling2D((7, 7), strides=(1, 1), padding='valid')(x)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(num_classes, activation='softmax', kernel_initializer=initializer, kernel_regularizer=l2(1e-3))(x)\n",
    "\n",
    "    # Final model\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=[x, aux_output1, aux_output2])\n",
    "    return model\n",
    "\n",
    "# Create and summarize the model\n",
    "model = GoogleNet(input_shape=(224, 224, 3), num_classes=101)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:24:00.046406Z",
     "iopub.status.busy": "2024-12-12T17:24:00.045533Z",
     "iopub.status.idle": "2024-12-12T17:24:00.052107Z",
     "shell.execute_reply": "2024-12-12T17:24:00.051190Z",
     "shell.execute_reply.started": "2024-12-12T17:24:00.046369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "@register_keras_serializable()\n",
    "def spatial_attention(inputs):\n",
    "    # Your spatial attention logic here\n",
    "    avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "    max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)\n",
    "    return tf.concat([avg_pool, max_pool], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:24:04.459100Z",
     "iopub.status.busy": "2024-12-12T17:24:04.458724Z",
     "iopub.status.idle": "2024-12-12T17:24:11.783082Z",
     "shell.execute_reply": "2024-12-12T17:24:11.782112Z",
     "shell.execute_reply.started": "2024-12-12T17:24:04.459067Z"
    },
    "id": "DM-HGO05f8iL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.config import enable_unsafe_deserialization\n",
    "\n",
    "# Enable unsafe deserialization\n",
    "enable_unsafe_deserialization()\n",
    "\n",
    "# Load the model\n",
    "model = load_model('/kaggle/input/model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:24:14.931809Z",
     "iopub.status.busy": "2024-12-12T17:24:14.931097Z",
     "iopub.status.idle": "2024-12-12T17:24:14.937346Z",
     "shell.execute_reply": "2024-12-12T17:24:14.936373Z",
     "shell.execute_reply.started": "2024-12-12T17:24:14.931734Z"
    },
    "id": "3Hdx-scCqdDF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def sparse_categorical_crossentropy_with_label_smoothing(y_true, y_pred, num_classes, smoothing=0.05):\n",
    "    \"\"\"\n",
    "    Custom sparse categorical crossentropy with label smoothing.\n",
    "\n",
    "    Args:\n",
    "        y_true: Tensor of shape (batch_size,) containing true class indices.\n",
    "        y_pred: Tensor of shape (batch_size, num_classes) containing predicted probabilities.\n",
    "        num_classes: Number of classes.\n",
    "        smoothing: Smoothing factor (float between 0 and 1).\n",
    "\n",
    "    Returns:\n",
    "        Scalar loss value.\n",
    "    \"\"\"\n",
    "    # Apply label smoothing\n",
    "    confidence = 1.0 - smoothing\n",
    "    low_confidence = smoothing / (num_classes - 1)\n",
    "\n",
    "    # Convert sparse labels to one-hot\n",
    "    y_true_one_hot = tf.one_hot(y_true, depth=num_classes)\n",
    "\n",
    "    # Smooth the labels\n",
    "    # Smooth the labels correctly\n",
    "    y_true_smoothed = y_true_one_hot * confidence + (1 - y_true_one_hot) * low_confidence\n",
    "\n",
    "    # Compute cross-entropy loss\n",
    "    loss = -tf.reduce_sum(y_true_smoothed * tf.math.log(y_pred + 1e-7), axis=-1)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:24:47.365218Z",
     "iopub.status.busy": "2024-12-12T17:24:47.364890Z",
     "iopub.status.idle": "2024-12-12T18:00:21.237208Z",
     "shell.execute_reply": "2024-12-12T18:00:21.235893Z",
     "shell.execute_reply.started": "2024-12-12T17:24:47.365190Z"
    },
    "id": "lrMKPv72f8iL",
    "outputId": "45a9e77c-a6a8-4eb7-c755-45a756b922fb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.000001,  # Initial LR\n",
    "    decay_steps=250,             # Number of steps after which LR decays\n",
    "    decay_rate=0.95,              # Decay rate (reduce LR by 4% every 1000 steps)\n",
    "    staircase=True                # Use discrete (staircase) decay\n",
    ")\n",
    "# Updated loss function: sum of main loss and auxiliary losses\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "best_val_acc = 0.8002\n",
    "\n",
    "# Path to save the best weights\n",
    "best_weights_filepath = \"/kaggle/working/best_weights.weights.h5\"\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Metrics\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "train_loss_metric = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "val_loss_metric = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass: Get main and auxiliary predictions\n",
    "        main_pred, aux_pred1, aux_pred2 = model(images, training=True)\n",
    "\n",
    "        # Compute individual losses\n",
    "        main_loss = sparse_categorical_crossentropy_with_label_smoothing(labels, main_pred, 101, smoothing=0)\n",
    "        aux_loss1 = sparse_categorical_crossentropy_with_label_smoothing(labels, aux_pred1, 101, smoothing=0)\n",
    "        aux_loss2 = sparse_categorical_crossentropy_with_label_smoothing(labels, aux_pred2, 101, smoothing=0)\n",
    "\n",
    "        # Combine losses (weight auxiliary losses lower)\n",
    "        total_loss = main_loss\n",
    "\n",
    "    # Backward pass: Compute gradients\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    # Update metrics\n",
    "    train_acc_metric.update_state(labels, main_pred)\n",
    "    train_loss_metric.update_state(total_loss)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "@tf.function\n",
    "def val_step(images, labels):\n",
    "    # Forward pass: Get predictions\n",
    "    main_pred, _, _ = model(images, training=False)\n",
    "\n",
    "    # Compute loss and update metrics\n",
    "    val_loss = loss_fn(labels, main_pred)\n",
    "    val_acc_metric.update_state(labels, main_pred)\n",
    "    val_loss_metric.update_state(val_loss)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    # Training loop\n",
    "    for step, (images, labels) in enumerate(train_dataset):\n",
    "        loss = train_step(images, labels)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}: Loss = {loss.numpy():.4f}, Accuracy = {train_acc_metric.result().numpy():.4f}\")\n",
    "\n",
    "    # Compute training metrics\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_loss = train_loss_metric.result()\n",
    "    train_acc_metric.reset_state()\n",
    "    train_loss_metric.reset_state()\n",
    "\n",
    "    # Validation loop\n",
    "    for images, labels in val_dataset:\n",
    "        val_step(images, labels)\n",
    "\n",
    "    # Compute validation metrics\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_loss = val_loss_metric.result()\n",
    "    val_acc_metric.reset_state()\n",
    "    val_loss_metric.reset_state()\n",
    "\n",
    "    print(f\"Training Accuracy: {train_acc:.4f}, Training Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        model.save_weights(best_weights_filepath)  # Save the best weights to a file\n",
    "        print(f\"Saved best weights with validation accuracy: {best_val_acc:.4f}\")\n",
    "model.load_weights(best_weights_filepath)\n",
    "print(f\"Restored best weights from file with validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get a batch of images and labels from the validation dataset\n",
    "for images, labels in val_dataset.take(1):  # Take one batch\n",
    "    # Get predictions\n",
    "    main_pred, _, _ = model(images, training=False)\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    predicted_labels = tf.argmax(main_pred, axis=1)\n",
    "\n",
    "    # Plot images and show predicted vs. true labels\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i in range(9):  # Display first 9 images\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(f\"True: {labels[i].numpy()}, Pred: {predicted_labels[i].numpy()}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:00:30.208033Z",
     "iopub.status.busy": "2024-12-12T18:00:30.207181Z",
     "iopub.status.idle": "2024-12-12T18:00:30.787078Z",
     "shell.execute_reply": "2024-12-12T18:00:30.786167Z",
     "shell.execute_reply.started": "2024-12-12T18:00:30.207996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(best_weights_filepath)\n",
    "print(f\"Restored best weights from file with validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:00:37.423097Z",
     "iopub.status.busy": "2024-12-12T18:00:37.422723Z",
     "iopub.status.idle": "2024-12-12T18:00:38.060363Z",
     "shell.execute_reply": "2024-12-12T18:00:38.059637Z",
     "shell.execute_reply.started": "2024-12-12T18:00:37.423065Z"
    },
    "id": "l48GYJypf8iL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "modelId": 189533,
     "modelInstanceId": 167214,
     "sourceId": 196111,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189706,
     "modelInstanceId": 167390,
     "sourceId": 196307,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189766,
     "modelInstanceId": 167449,
     "sourceId": 196372,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189805,
     "modelInstanceId": 167489,
     "sourceId": 196414,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 189848,
     "modelInstanceId": 167532,
     "sourceId": 196460,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 190206,
     "modelInstanceId": 167859,
     "sourceId": 196839,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
